{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "env_vars = {\n",
    "    \"OPENAI_API_KEY\": \"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\",\n",
    "}\n",
    "\n",
    "def pretty_print_docs(docs):\n",
    "    print(f\"\\n{'-' * 100}\\n\".join([f\"Document {i+1}:\\n\" + d.page_content for i, d in enumerate(docs)]))\n",
    "\n",
    "for key, value in env_vars.items():\n",
    "    os.environ[key] = value\n",
    "\n",
    "embedding = OpenAIEmbeddings(chunk_size=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "from langchain.schema import Document\n",
    "\n",
    "# Load blog post\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"./dogs.txt\")\n",
    "data = loader.load()\n",
    "loader = TextLoader(\"./restaurant.txt\")\n",
    "data2 = loader.load()\n",
    "\n",
    "docs = data + data2\n",
    "\n",
    "\n",
    "#text_splitter = RecursiveCharacterTextSplitter(chunk_size=120, chunk_overlap=10)\n",
    "#docs = text_splitter.split_documents(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector1 = embedding.embed_query(\"How is the whether??\")\n",
    "vector2 = embedding.embed_query(\"What is the Name of the Dogschool?\")\n",
    "vector3 = embedding.embed_query(\"What food do you offer?\")\n",
    "\n",
    "data_vectors = [embedding.embed_query(doc.page_content) for doc in docs]\n",
    "print(len(data_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "cosine_sims_1 = [cosine_similarity([vector1], [data_vector])[0][0] for data_vector in data_vectors]\n",
    "cosine_sims_2 = [cosine_similarity([vector2], [data_vector])[0][0] for data_vector in data_vectors]\n",
    "cosine_sims_3 = [cosine_similarity([vector3], [data_vector])[0][0] for data_vector in data_vectors]\n",
    "\n",
    "x = np.arange(len(data_vectors))\n",
    "\n",
    "plt.scatter(x, cosine_sims_1, label='Weather', alpha=0.7)\n",
    "plt.scatter(x, cosine_sims_2, label='Dogschool', alpha=0.7)\n",
    "plt.scatter(x, cosine_sims_3, label='Restaurant', alpha=0.7)\n",
    "\n",
    "plt.ylabel('Cosine Similarity')\n",
    "plt.title('Consine Similarity between query and data vectors')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "\n",
    "child_splitter = RecursiveCharacterTextSplitter(chunk_size=120, chunk_overlap=20)\n",
    "parent_splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=20)\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"full_documents\", embedding_function=embedding\n",
    ")\n",
    "store = InMemoryStore()\n",
    "retriever = ParentDocumentRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=store,\n",
    "    child_splitter=child_splitter,\n",
    "    parent_splitter=parent_splitter\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.add_documents(docs, ids=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore.similarity_search(\"What is the name of the dog school?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.get_relevant_documents(\"What is the name of the dog school?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultiQueryRetriever\n",
    "\n",
    "Nuances in the question can lead to different results if the question does not capture the embeddings semantically well.\n",
    "MultiQueryRetriever creates variations of the question and thus goes against the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "        temperature=0,\n",
    "        max_tokens=800,\n",
    "        model_kwargs={\"top_p\": 0, \"frequency_penalty\": 0, \"presence_penalty\": 0},\n",
    "    )\n",
    "\n",
    "\n",
    "retriever = MultiQueryRetriever.from_llm(\n",
    "    retriever=vectorstore.as_retriever(), llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_docs = retriever.get_relevant_documents(\"What is the name of the dog school?\")\n",
    "len(unique_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class LineList(BaseModel):\n",
    "    lines: List[str] = Field(description=\"Lines of text\")\n",
    "\n",
    "\n",
    "class LineListOutputParser(PydanticOutputParser):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__(pydantic_object=LineList)\n",
    "\n",
    "    def parse(self, text: str) -> LineList:\n",
    "        lines = text.strip().split(\"\\n\")\n",
    "        return LineList(lines=lines)\n",
    "\n",
    "\n",
    "output_parser = LineListOutputParser()\n",
    "\n",
    "QUERY_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"You are an AI language model assistant. Your task is to generate five\n",
    "    different versions of the given user question to retrieve relevant documents from a vector\n",
    "    database. By generating multiple perspectives on the user question, your goal is to help\n",
    "    the user overcome some of the limitations of the distance-based similarity search.\n",
    "    Provide these alternative questions separated by newlines.\n",
    "    Original question: {question}\"\"\",\n",
    ")\n",
    "\n",
    "llm_chain = LLMChain(llm=llm, prompt=QUERY_PROMPT, output_parser=output_parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain.invoke(\"What is the name of the dog school?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is the name of the dog school?\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contextual Compression\n",
    "\n",
    "To use the Contextual Compression Retriever, you need:\n",
    "\n",
    "    a basic retriever\n",
    "    a document compressor\n",
    "\n",
    "The Contextual Compression Retriever passes queries to the Base Retriever, takes the source documents and forwards them to the Document Compressor. The document compressor takes a list of documents and shortens them by reducing the content of documents or omitting documents altogether."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma(\n",
    "    collection_name=\"full_documents\", embedding_function=embedding\n",
    ")\n",
    "vectorstore.add_documents(docs)\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.get_relevant_documents(query=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "\n",
    "compressor = LLMChainExtractor.from_llm(llm)\n",
    "compression_retriever = ContextualCompressionRetriever(base_compressor=compressor, base_retriever=retriever)\n",
    "\n",
    "compressed_docs = compression_retriever.get_relevant_documents(query=question)\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.retrievers.document_compressors import EmbeddingsFilter\n",
    "\n",
    "embeddings_filter = EmbeddingsFilter(embeddings=embedding, similarity_threshold=0.5)\n",
    "compression_retriever = ContextualCompressionRetriever(base_compressor=embeddings_filter, base_retriever=retriever)\n",
    "\n",
    "compressed_docs = compression_retriever.get_relevant_documents(query=question)\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_transformers import EmbeddingsRedundantFilter\n",
    "from langchain.retrievers.document_compressors import DocumentCompressorPipeline\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "splitter = CharacterTextSplitter(chunk_size=300, chunk_overlap=0, separator=\". \")\n",
    "redundant_filter = EmbeddingsRedundantFilter(embeddings=embedding)\n",
    "relevant_filter = EmbeddingsFilter(embeddings=embedding, similarity_threshold=0.76)\n",
    "pipeline_compressor = DocumentCompressorPipeline(\n",
    "    transformers=[splitter, redundant_filter, relevant_filter]\n",
    ")\n",
    "\n",
    "compression_retriever = ContextualCompressionRetriever(base_compressor=pipeline_compressor, base_retriever=retriever)\n",
    "\n",
    "compressed_docs = compression_retriever.get_relevant_documents(query=question)\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "\n",
    "\n",
    "bm25_retriever = BM25Retriever.from_documents(docs)\n",
    "bm25_retriever.k = 2\n",
    "\n",
    "chroma_vectorstore = Chroma.from_documents(docs, embedding)\n",
    "chroma_retriever = chroma_vectorstore.as_retriever()\n",
    "\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, chroma_retriever], weights=[0.5, 0.5]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = ensemble_retriever.get_relevant_documents(query=question)\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-Querying retriever\n",
    "\n",
    "A self-querying retriever is a retriever that, as the name suggests, has the ability to \n",
    "the ability to query itself. More precisely, any natural language query,\n",
    " the retriever uses an LLM chain for query construction to write a structured query\n",
    " structured query and then applies this structured query to the underlying \n",
    "VectorStore. This allows the retriever to not only use the query entered by the user \n",
    "query for the semantic similarity comparison with the content of the stored \n",
    "documents, but also apply filters from the user query to the metadata of the stored \n",
    "metadata of the stored documents and execute these filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "docs = [\n",
    "    Document(\n",
    "        page_content=\"Bello-Basistraining offers a comprehensive foundation for dog obedience, focusing on basic commands and socialization.\",\n",
    "        metadata={\"type\": \"Basic Training\", \"feature\": \"Foundational Skills\", \"price\": \"Affordable\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Pfote-Agilitykurs provides a fun and energetic way to keep dogs fit and mentally stimulated through obstacle courses.\",\n",
    "        metadata={\"type\": \"Agility Training\", \"feature\": \"Physical Fitness\", \"price\": \"Moderate\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Wuff-Verhaltensberatung specializes in addressing behavioral issues, offering tailored strategies for each dog.\",\n",
    "        metadata={\"type\": \"Behavioral Consultation\", \"feature\": \"Customized Solutions\", \"price\": \"Premium\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Schwanzwedeln-Therapiehundausbildung prepares dogs for roles in therapeutic and support settings, focusing on empathy and gentleness.\",\n",
    "        metadata={\"type\": \"Therapy Dog Training\", \"feature\": \"Emotional Support\", \"price\": \"High\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Schn√ºffler-Suchhundetraining trains dogs in scent detection, useful for search and rescue operations.\",\n",
    "        metadata={\"type\": \"Search and Rescue Training\", \"feature\": \"Advanced Skills\", \"price\": \"Variable\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Hunde-Haftpflichtversicherung offers comprehensive coverage for potential damages or injuries caused by your dog.\",\n",
    "        metadata={\"type\": \"Dog Liability Insurance\", \"feature\": \"Financial Protection\", \"price\": \"Varies\"},\n",
    "    ),\n",
    "]\n",
    "\n",
    "vectorstore = Chroma.from_documents(docs, embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "\n",
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"type\",\n",
    "        description=\"The type of dog training service (e.g., Basic Training, Agility Training, Behavioral Consultation)\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"feature\",\n",
    "        description=\"Special features or benefits of the service\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"price\",\n",
    "        description=\"Price category of the service (e.g., Affordable, Moderate, Premium)\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "document_content_description = \"Description of a dog training service\"\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vectorstore,\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.invoke(\"What Premium priced trainings do you offer?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-weighted vector store retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from langchain.docstore import InMemoryDocstore\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.retrievers import TimeWeightedVectorStoreRetriever\n",
    "from langchain.schema import Document\n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# decay_rate = .0000000000000000000000001\n",
    "decay_rate = .999\n",
    "\n",
    "embedding_size = 1536\n",
    "index = faiss.IndexFlatL2(embedding_size)\n",
    "vectorstore = FAISS(embedding, index, InMemoryDocstore({}), {})\n",
    "retriever = TimeWeightedVectorStoreRetriever(vectorstore=vectorstore, decay_rate=decay_rate, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yesterday = datetime.now() - timedelta(days=1)\n",
    "retriever.add_documents([Document(page_content=\"hello world\", metadata={\"last_accessed_at\": yesterday})])\n",
    "retriever.add_documents([Document(page_content=\"hello foo\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.get_relevant_documents(\"hello world\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  },
  "kernelspec": {
   "display_name": "Python 3.9.15 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
